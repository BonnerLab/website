- title: "Universal scale-free representations in human visual cortex"
  image: scale_free_reps.png
  description: Is it possible to deeply understand neural representations through dimensionality reduction? Our recent work demonstrates that the visual representations in the human brain require interpretation within high-dimensional spaces. Moreover, we reveal that traditional methods like representational similarity analysis fail to detect this high-dimensional information in cortical activity; instead, a spectral approach is necessary. This research uncovers a vast expanse of uncharted dimensions that conventional techniques have overlooked but may be crucial for decoding the cortical code of human vision.
  authors: Raj Magesh Gauthaman, Brice MÃ©nard, Michael F. Bonner
  link:
    url: https://arxiv.org/abs/2409.06843
    display: Arxiv (2024)
  highlight: 1


- title: "Universal dimensions of visual representation"
  image: universal_dim.png
  description: We examined whether visual neural networks align with brain representations due to shared constraints or universal features. Analysis of diverse networks revealed shared latent dimensions for image representation. Comparing these to human fMRI data showed brain-aligned representations are universal across networks. This suggests similarities between artificial and biological vision arise from core universal image representations learned convergently.
  authors: Zirui Chen, Michael F. Bonner
  link:
    url: https://arxiv.org/abs/2408.12804
    display: Arxiv (2024)
  highlight: 1

- title: "Convolutional architectures are cortex-aligned de novo"
  image: untrained_cortex_alignment.png
  description: We find that untrained convolutional neural networks can produce brain-like visual representations. This challenges the view that extensive training is necessary for such similarities. The key factors are the networks' architecture, specifically how they compress spatial information and expand feature information. This suggests that the basic structure of convolutional networks mimics biological vision constraints, allowing for cortex-like representations even without learning from experience.
  authors: Atlas Kazemian, Eric Elmoznino, Michael F. Bonner
  link:
    url: https://www.biorxiv.org/content/biorxiv/early/2024/05/14/2024.05.10.593623.full.pdf
    display: BioRxiv (2024)
  highlight: 1  

- title: "High-performing neural network models of visual cortex benefit from high latent dimensionality"
  image: high_dimensionality.png
  description: Investigating deep neural networks (DNNs) as models for the visual cortex, we found that higher-dimensional representations in these networks better predict cortical responses and improve learning of new stimuli, challenging the idea that lower dimensionality enhances performance. This indicates that high-dimensional geometries might be advantageous for DNN models of visual processing.
  authors: Eric Elmoznino, Michael F. Bonner
  link:
    url: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011792
    display: PLOS Computational Biology (2023)
  highlight: 1   

- title: "TUTORIAL: A High-Dimensional View of Neuroscience."
  image: mick_ccn.png
  description: With technological advances allowing us to capture neural responses to thousands of stimuli across numerous channels (e.g., human fMRI, mouse two-photon imaging, monkey neuropixel probes), we face the challenge of analyzing vast, costly datasets. We must consider which computational tools are best suited for high-dimensional neural representation studies and what theoretical insights we can derive about neural representations from these large-scale datasets.
  authors: Raj Magesh Gauthaman, Florentin Guth, Atlas Kazemian, Zirui Chen, Michael F. Bonner
  link:
    url: https://bonnerlab.github.io/ccn-tutorial/
    display: Cognitive Computational Neuroscience (2023)
  highlight: 1
  news1: Visit ^website for tutorial materials.


- title: Hierarchical organization of social action features along the lateral visual pathway
  authors: Emalie McMahon, Michael F. Bonner, Leyla Isik
  image: social_action_features.png
  description: The lateral stream's organization, thought to be hierarchical like in the ventral and dorsal streams, has not been thoroughly studied for naturalistic, social visuals. We compiled 250 3-second videos of everyday interactions between two people, annotated for visual features from low-level to high-level, including scene properties, social dynamics, and emotional content.
  link:
    url: https://pubmed.ncbi.nlm.nih.gov/37918399/
    display: Cell Current Biology (2023)
  highlight: 1 


- title: Perceived Distance Alters Memory for Scene Boundaries
  authors: Alon Hafri, Shreya Wadhwa, Michael F. Bonner
  image: perceived_distance.png
  description: What factors determine when visual memories will include details that go beyond perceptual experience? Here, seven experiments (N = 1,100 adults) explored whether spatial scale-specifically, perceived viewing distance-drives boundary extension. We created fake miniatures by exploiting tilt shift, a photographic effect that selectively reduces perceived distance while preserving other scene properties (e.g., making a distant railway appear like a model train). We found that visual memory is modulated by the spatial scale at which the environment is viewed.
  link:
    url: https://pubmed.ncbi.nlm.nih.gov/36206190/
    display: Psychological Science (2022)
  highlight: 1

- title: Object representations in the human brain reflect the co-occurrence statistics of vision and language
  authors: Michael F. Bonner, Russell Epstein
  image: obj_to_vec.png
  description: Using machine learning and fMRI, we tested if the human visual system encodes object co-occurrence statistics, revealed through individual object perception. We identified low-dimensional representations of these statistics in real-world scenes and correlated them with voxel-wise fMRI responses during object viewing. Our findings indicate cortical responses to single objects are influenced by their typical statistical contexts, highlighting brain regions where this connection is strongest.
  link:
    url: https://www.nature.com/articles/s41467-021-24368-2
    display: Nature Communications (2021)
  highlight: 1

